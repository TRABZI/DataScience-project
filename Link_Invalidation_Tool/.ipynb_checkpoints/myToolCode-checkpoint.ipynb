{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Owlready2\n",
    "!pip install rdflib\n",
    "!pip install python-Levenshtein\n",
    "!pip install distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile, requests\n",
    "import rdflib\n",
    "import difflib\n",
    "import distance\n",
    "import distance, Levenshtein\n",
    "import tarfile, requests\n",
    "\n",
    "from owlready2 import *\n",
    "from dateutil import parser\n",
    "from owlready2 import *\n",
    "from rdflib import Graph\n",
    "from sklearn.metrics import precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get dataset from URL\n",
    "IIMB_dataset = \"http://oaei.ontologymatching.org/2010/im/iimb_large_30082010.tgz\"\n",
    "target_path = 'iimb_large_30082010.tgz'\n",
    "\n",
    "response = requests.get(IIMB_dataset, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(target_path, 'wb') as f:\n",
    "        f.write(response.raw.read())\n",
    "\n",
    "#extract tar file\n",
    "tar = tarfile.open(target_path, 'r')\n",
    "for item in tar:\n",
    "  tar.extract(item, \".\")\n",
    "\n",
    "\n",
    "onto = get_ontology(\"file:///content/IIMB_LARGE/000/onto.owl\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"file:///content/IIMB_LARGE/000/onto.owl\").load()\n",
    "onto2 = get_ontology(\"file:///content/IIMB_LARGE/001/onto.owl\").load()\n",
    "\n",
    "def Func(a,b):\n",
    "    func=a/b  \n",
    "    return func\n",
    "    \n",
    "def get_func_prop(onto,threshold):    \n",
    "    properties=[]\n",
    "    str_properties=[]\n",
    "    num_duplic_properties=[]\n",
    "    num_uniq_properties=[]\n",
    "\n",
    "    for i in onto.properties():\n",
    "        properties.append(i)\n",
    "    \n",
    "    buffer1=0\n",
    "    for i in properties:\n",
    "        str_properties.append(str(i).split('.')[1])\n",
    "        buffer1=len(list(i.get_relations()))\n",
    "        num_duplic_properties.append(buffer1)\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    get_rel=[]\n",
    "    num_uniq_properties=[]\n",
    "    func_prop={}\n",
    "    for n in properties:\n",
    "        uniq_prop_relations=[]\n",
    "        get_rel=list(properties[i].get_relations())\n",
    "        for k in get_rel: \n",
    "            if k[0] not in uniq_prop_relations:\n",
    "                uniq_prop_relations.append(k[0])\n",
    "        num_uniq_properties.append(len(uniq_prop_relations))\n",
    "        a=num_uniq_properties[j]\n",
    "        b=num_duplic_properties[j]\n",
    "        if b!=0:\n",
    "            func_prop[n]=Func(a,b)\n",
    "        j=j+1    \n",
    "        i=i+1\n",
    "        \n",
    "        # Threshold 1 -------------------------\n",
    "    print(\"Functionnal properties, After threshold=%d applied: \\n \"%threshold)\n",
    "    validated_func_properties=[]\n",
    "    threshold=1\n",
    "    for i in func_prop: \n",
    "        if func_prop[i]>=threshold:\n",
    "            validated_func_properties.append(i)\n",
    "    print(\"propertiesFunctionality:\\n\",func_prop)\n",
    "    print(\"validatedFuncPropeties:\\n\",validated_func_properties)\n",
    "\n",
    "    #print(\"\\nlen(validated_func_properties)=\",len(validated_func_properties))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return validated_func_properties\n",
    "\n",
    "func_prop=get_func_prop(onto,1)\n",
    "#del func_prop[-len(func_prop)+1]\n",
    " \n",
    "\n",
    "print(\"func_prop:\\n\",func_prop)\n",
    "objectProperties={}\n",
    "dataTypProperties={}\n",
    "dataProp=[]\n",
    "for prop in onto.object_properties():\n",
    "        if prop in func_prop:\n",
    "            name = str(prop).split('.')[1]\n",
    "            objectProperties[name]=1\n",
    "print(\"objectProperties:\\n\",objectProperties)\n",
    "\n",
    "for prop in onto.data_properties():\n",
    "        if prop in func_prop:\n",
    "            name = str(prop).split('.')[1]\n",
    "            dataTypProperties[name]=1\n",
    "            dataProp.append(prop)\n",
    "print(\"\\ndataTypProperties:\\n\",dataTypProperties)\n",
    "print(dataProp)\n",
    "\n",
    "\n",
    "file_name=\"refalign.rdf\"\n",
    "directory=os.path.join('IIMB_LARGE/001',file_name)\n",
    "print(directory)\n",
    " \n",
    "full_path_file=os.path.abspath(directory)\n",
    "print(\"\\n\",full_path_file)\n",
    "\n",
    "g_ref = Graph()\n",
    "g_ref.parse(full_path_file, format=\"xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prop(entity1,entity2,Property,scoreList):\n",
    "    \n",
    "    if Property==\"gender\":\n",
    "        ent1=str(getattr(entity1,str(Property))[0]).lower()[0]\n",
    "        ent2=str(getattr(entity2,str(Property))[0]).lower()[0]\n",
    "                     \n",
    "    elif Property==\"name\":\n",
    "        ent1=str(entity1.__getattr__(Property)[0]).lower()\n",
    "        ent2=str(entity2.__getattr__(Property)[0]).lower()\n",
    "                        \n",
    "    elif Property==\"amount\":\n",
    "        ent1 = str(float(str(getattr(entity1,Property)[0])))\n",
    "        ent2 = str(float(str(getattr(entity2,Property)[0])))\n",
    "                    \n",
    "    else:\n",
    "        ent1=str(getattr(entity1,str(Property))[0]).lower().replace(\"-\", \"/\")\n",
    "        ent2=str(getattr(entity2,str(Property))[0]).lower().replace(\"-\", \"/\")\n",
    "                        \n",
    "    leven = Levenshtein.ratio(ent1, ent2) \n",
    "    jac = 1 - distance.jaccard(ent1, ent2)\n",
    "    sor = 1 - distance.sorensen(ent1, ent2)\n",
    "    scoreList.append((leven + sor + jac)/3)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool\n",
    "\n",
    "def tool(g_ref,onto,onto2,func_prop,dataProp,dataTypProperties,objectProperties,conf):\n",
    "    \n",
    "    ref_qres = g_ref.query(\"SELECT ?a ?b WHERE {?c a <http://knowledgeweb.semanticweb.org/heterogeneity/alignment#Cell> ; <http://knowledgeweb.semanticweb.org/heterogeneity/alignment#entity1> ?a; <http://knowledgeweb.semanticweb.org/heterogeneity/alignment#entity2> ?b . }\")\n",
    "\n",
    "    ground_true = []\n",
    "    measures_predicted = []\n",
    "    false_detected_rules=[]\n",
    "\n",
    "    counter=0\n",
    "    for row in ref_qres:\n",
    "        ground_true.append(1)\n",
    "        entity1 = onto.search_one(iri = str(row[0]))\n",
    "        entity2 = onto2.search_one(iri = str(row[1]))\n",
    "        #print(entity1,entity2)\n",
    "\n",
    "        scoreList=[]\n",
    "        for p in func_prop:\n",
    "            \n",
    "            Property=str(p).split('.')[1]\n",
    "\n",
    "            if Property in dataTypProperties:\n",
    "                a=[r[0] for r in p.get_relations()]\n",
    "                if entity1 in a and entity2 in a:\n",
    "                    compare_prop(entity1,entity2,Property,scoreList)\n",
    "\n",
    "            if Property in objectProperties:\n",
    "                b=[r[0] for r in p.get_relations()]\n",
    "                #print(b)\n",
    "                if entity1 in b and entity2 in b:\n",
    "                    #print(\"##### objProperty:\",Property)\n",
    "                    #print(str(getattr(entity1,str(Property))).lower())\n",
    "                    #print(str(getattr(entity2,str(Property))).lower())\n",
    "                    propComp1 = getattr(entity1,str(Property))[0]\n",
    "                    propComp2 = getattr(entity2,str(Property))[0]\n",
    "                    #print(\"propComp1:\",propComp1)\n",
    "                    #print(\"propComp2:\",propComp2)\n",
    "\n",
    "                    for ii in dataProp:\n",
    "                        Prop=str(ii).split('.')[1]\n",
    "                        cc=[rr[0] for rr in ii.get_relations()]\n",
    "                        #print(cc)\n",
    "                        if propComp1 in cc and propComp2 in cc:\n",
    "                            #print(\"-->found property:\",Prop)\n",
    "                            compare_prop(propComp1,propComp1,Prop,scoreList)\n",
    "                            \n",
    "        if len(scoreList)!=0:\n",
    "            if sum(scoreList)/len(scoreList) >= conf:\n",
    "                measures_predicted.append(1)\n",
    "            else:\n",
    "                measures_predicted.append(0)\n",
    "                false_detected_rules.append((str(row[0]),str(row[1])))\n",
    "        else:\n",
    "            measures_predicted.append(0)\n",
    "            false_detected_rules.append((str(row[0]),str(row[1])))\n",
    "        #counter+=1  \n",
    "        #if counter==20:\n",
    "        #break\n",
    "\n",
    "    print(false_detected_rules)\n",
    "    metrics = precision_recall_fscore_support(ground_true, measures_predicted, average='micro')\n",
    "    print(\"---------------------\")\n",
    "    print(\"Precision: %f\"%metrics[0])\n",
    "    print(\"Recall: %f\"%metrics[1])\n",
    "    print(\"F-score: %f\"%metrics[2])\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
